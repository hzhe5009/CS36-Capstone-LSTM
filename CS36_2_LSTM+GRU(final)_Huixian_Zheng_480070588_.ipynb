{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS36-2 LSTM+GRU Huixian Zheng 480070588 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hzhe5009/CS36-Capstone-LSTM/blob/master/CS36_2_LSTM%2BGRU(final)_Huixian_Zheng_480070588_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxaM2Jgg1akR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, LeakyReLU,Dropout, LSTM, concatenate,Input # When runing GRU model, change 'LSTM' into 'GRU' here.\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot\n",
        "from datetime import datetime, timedelta, time\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKjYWzdEjNJc",
        "colab_type": "code",
        "outputId": "83d13ce0-eaee-4d99-8de6-89227d7132aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Mount Google drive on virtual machine\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RpCB7bP36_e",
        "colab_type": "code",
        "outputId": "ae19d028-7945-46c5-aeb2-14662b21a512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# define neural network model\n",
        "model = Sequential()\n",
        "# When runing GRU model, change 'LSTM' into 'GRU' here and when adjusting timestep, change 45 in batch_input_shape into 15,30,60,75 and 90.\n",
        "model.add(LSTM(512, batch_input_shape=(None, 45, 32+7+25+60+265+1))) \n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(265))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32))\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "print(model.summary())\n",
        "# When adjusting learning_rate, change 0.0001 into 0.001 and 0.0005\n",
        "adam = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "# compile the model\n",
        "model.compile(loss='mean_squared_error', metrics=['mse', 'mae', 'mape'], optimizer=adam)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 512)               1849344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 265)               135945    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 265)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 265)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                8512      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,256,490\n",
            "Trainable params: 2,256,490\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DlMIRZPZjZfv",
        "colab": {}
      },
      "source": [
        "# Getting data from google drive\n",
        "data_path = '/content/gdrive/My Drive/ctx/combine_data/partzone3month.csv'\n",
        "new_select_data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FcuyRzZBucO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data preprocessing for LSTM and GRU model\n",
        "\n",
        "# Using 'pickup_time_g' to create index which will be used later to aggregate data\n",
        "new_select_data['pickup_time_g_index'] = pd.to_datetime(new_select_data['pickup_time_g']) \n",
        "new_select_data['pickup_time_g'] = new_select_data['pickup_time_g_index'].copy() \n",
        "new_select_data.set_index('pickup_time_g_index',inplace=True)\n",
        "\n",
        "# Create a list with number from 1 to 4000 and randomly select 40 numbers in those numbers.\n",
        "split_size = 4000\n",
        "num_epochs = 5\n",
        "loop_list = random.sample(range(0, split_size), int(split_size/100))\n",
        "\n",
        "# Aggregate data using LocationID \n",
        "new_select_grouper = new_select_data.groupby('LocationID') \n",
        "del new_select_data # Delete useless data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZpvVQfvJBwq",
        "colab_type": "code",
        "outputId": "136f6c9d-b9d1-4099-cbea-111352707cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Data preprocessing for LSTM and GRU model\n",
        "\n",
        "# Split data into multiple batches and using the random numbers getting from previous stages to randomly select batches used to train the mode\n",
        "# and change 'day','weekday', 'hour','minute','LocationID','minute_demand' and '15_demand' into categorical \n",
        "# because in real life attributes like 'day' is not continous and it usually just has 30 values.\n",
        "split_list ={}\n",
        "val_loss = 0\n",
        "for i in loop_list:\n",
        "  train_data,label_data = [],[]\n",
        "  for each_loc in new_select_grouper:\n",
        "    location_data = each_loc[1]\n",
        "    if i == loop_list[0]:\n",
        "      random_location_data = location_data.sample(frac=1, random_state=2020)\n",
        "      split_list[each_loc[0]]  = np.array_split(random_location_data, split_size)\n",
        "    location_df_list = split_list[each_loc[0]] \n",
        "    first_time = True\n",
        "    for index, row in location_df_list[i].iterrows():\n",
        "      this_time = row['pickup_time_g']\n",
        "# Getting previous 45 mins data and when adjusting timestep, also change 'timedelta(minutes=45)' into 15, 30, 60, 65, 90\n",
        "      time_window = (location_data['pickup_time_g']>=this_time - timedelta(minutes=45))&(location_data['pickup_time_g']<=this_time - timedelta(minutes=1))\n",
        "      window_items = location_data[time_window]\n",
        "# when adjusting timestep, also change 'len(window_items) ==  45' into 15, 30, 60, 65, 90\n",
        "      if len(window_items) ==  45:\n",
        "          pu_day_cat = to_categorical(window_items['day'], num_classes=32)\n",
        "          pu_week_cat = to_categorical(window_items['weekday'], num_classes=7)\n",
        "          hour_cat = to_categorical(window_items['hour'], num_classes=25)\n",
        "          minute_cat = to_categorical(window_items['minute'], num_classes=60)\n",
        "          if first_time:\n",
        "            first_time = False\n",
        "            locat_cat = to_categorical(window_items['LocationID'], num_classes=265)\n",
        "          train_data.append(np.hstack((pu_day_cat,pu_week_cat,hour_cat,minute_cat,locat_cat,\n",
        "                                      window_items['minute_demand'].values.reshape(-1,1))))\n",
        "          label_data.append(row['15_demand'])\n",
        "\n",
        "  #Use data to train the model\n",
        "  train_data = np.array(train_data)\n",
        "  label_data = np.array(label_data)\n",
        "  # randomly split the data for training and evaluation\n",
        "  X_tr, X_val, y_tr, y_val = train_test_split(train_data, label_data, test_size=0.1, random_state=2020)\n",
        "  history = model.fit(X_tr, y_tr, epochs=3, verbose=2,validation_data=(X_val, y_val))\n",
        "  val_loss +=  model.evaluate(X_val, y_val, verbose=2)[-2]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122/122 - 39s - loss: 551.0303 - mse: 551.0229 - mae: 9.8755 - mape: 290600960.0000 - val_loss: 60.2607 - val_mse: 61.1231 - val_mae: 3.5314 - val_mape: 336434656.0000\n",
            "14/14 - 1s - loss: 60.2607 - mse: 61.1231 - mae: 3.5314 - mape: 336434656.0000\n",
            "118/118 - 35s - loss: 167.4003 - mse: 167.5484 - mae: 5.5688 - mape: 340001952.0000 - val_loss: 76.7657 - val_mse: 81.3977 - val_mae: 4.3685 - val_mape: 370087680.0000\n",
            "14/14 - 1s - loss: 76.7657 - mse: 81.3977 - mae: 4.3685 - mape: 370087680.0000\n",
            "118/118 - 35s - loss: 123.5002 - mse: 123.5991 - mae: 4.6648 - mape: 218066992.0000 - val_loss: 43.9631 - val_mse: 46.6774 - val_mae: 3.1125 - val_mape: 166746448.0000\n",
            "14/14 - 1s - loss: 43.9631 - mse: 46.6774 - mae: 3.1125 - mape: 166746448.0000\n",
            "118/118 - 35s - loss: 93.2099 - mse: 93.1254 - mae: 4.2988 - mape: 205992992.0000 - val_loss: 50.7179 - val_mse: 53.7867 - val_mae: 3.1969 - val_mape: 139036496.0000\n",
            "14/14 - 1s - loss: 50.7179 - mse: 53.7867 - mae: 3.1969 - mape: 139036496.0000\n",
            "118/118 - 35s - loss: 105.7818 - mse: 105.7650 - mae: 4.4649 - mape: 175527872.0000 - val_loss: 55.9698 - val_mse: 59.2050 - val_mae: 3.1423 - val_mape: 174779600.0000\n",
            "14/14 - 1s - loss: 55.9698 - mse: 59.2050 - mae: 3.1423 - mape: 174779600.0000\n",
            "118/118 - 35s - loss: 103.3450 - mse: 103.1132 - mae: 4.5345 - mape: 157444448.0000 - val_loss: 48.3407 - val_mse: 51.3230 - val_mae: 3.5247 - val_mape: 103301960.0000\n",
            "14/14 - 1s - loss: 48.3407 - mse: 51.3230 - mae: 3.5247 - mape: 103301960.0000\n",
            "118/118 - 36s - loss: 89.6129 - mse: 89.6532 - mae: 4.3000 - mape: 147779568.0000 - val_loss: 59.7446 - val_mse: 57.4943 - val_mae: 3.2606 - val_mape: 93541584.0000\n",
            "14/14 - 1s - loss: 59.7446 - mse: 57.4943 - mae: 3.2606 - mape: 93541584.0000\n",
            "118/118 - 37s - loss: 81.8575 - mse: 81.7263 - mae: 4.0196 - mape: 167138864.0000 - val_loss: 44.0954 - val_mse: 43.6438 - val_mae: 3.2096 - val_mape: 83050600.0000\n",
            "14/14 - 1s - loss: 44.0954 - mse: 43.6438 - mae: 3.2096 - mape: 83050600.0000\n",
            "118/118 - 35s - loss: 91.6399 - mse: 91.4569 - mae: 4.4524 - mape: 141037792.0000 - val_loss: 61.7215 - val_mse: 65.7001 - val_mae: 3.6104 - val_mape: 110807760.0000\n",
            "14/14 - 1s - loss: 61.7215 - mse: 65.7001 - mae: 3.6104 - mape: 110807760.0000\n",
            "118/118 - 35s - loss: 81.5732 - mse: 81.6435 - mae: 4.0750 - mape: 121750720.0000 - val_loss: 42.5142 - val_mse: 38.9139 - val_mae: 2.9911 - val_mape: 63772740.0000\n",
            "14/14 - 1s - loss: 42.5142 - mse: 38.9139 - mae: 2.9911 - mape: 63772740.0000\n",
            "118/118 - 36s - loss: 92.3897 - mse: 92.4982 - mae: 4.2780 - mape: 161138160.0000 - val_loss: 27.9656 - val_mse: 29.0860 - val_mae: 2.7299 - val_mape: 121687648.0000\n",
            "14/14 - 1s - loss: 27.9656 - mse: 29.0860 - mae: 2.7299 - mape: 121687648.0000\n",
            "118/118 - 35s - loss: 94.3331 - mse: 94.3724 - mae: 4.5663 - mape: 110014496.0000 - val_loss: 56.2295 - val_mse: 59.2804 - val_mae: 3.6111 - val_mape: 65492452.0000\n",
            "14/14 - 1s - loss: 56.2295 - mse: 59.2804 - mae: 3.6111 - mape: 65492452.0000\n",
            "118/118 - 35s - loss: 77.5691 - mse: 77.6506 - mae: 3.8134 - mape: 137164144.0000 - val_loss: 34.6544 - val_mse: 36.7087 - val_mae: 2.8309 - val_mape: 115265744.0000\n",
            "14/14 - 1s - loss: 34.6544 - mse: 36.7087 - mae: 2.8309 - mape: 115265744.0000\n",
            "118/118 - 35s - loss: 75.7344 - mse: 75.7526 - mae: 4.0113 - mape: 143092160.0000 - val_loss: 34.6445 - val_mse: 35.8658 - val_mae: 2.8987 - val_mape: 94120200.0000\n",
            "14/14 - 1s - loss: 34.6445 - mse: 35.8658 - mae: 2.8987 - mape: 94120200.0000\n",
            "118/118 - 36s - loss: 60.5508 - mse: 60.4996 - mae: 3.5396 - mape: 86916328.0000 - val_loss: 30.4341 - val_mse: 32.3633 - val_mae: 2.8007 - val_mape: 52990644.0000\n",
            "14/14 - 1s - loss: 30.4341 - mse: 32.3633 - mae: 2.8007 - mape: 52990644.0000\n",
            "118/118 - 35s - loss: 60.7918 - mse: 60.7859 - mae: 3.5524 - mape: 124591496.0000 - val_loss: 43.9240 - val_mse: 45.4493 - val_mae: 2.9114 - val_mape: 64260428.0000\n",
            "14/14 - 1s - loss: 43.9240 - mse: 45.4493 - mae: 2.9114 - mape: 64260428.0000\n",
            "118/118 - 35s - loss: 69.3215 - mse: 69.3638 - mae: 3.6800 - mape: 104854000.0000 - val_loss: 39.3637 - val_mse: 41.8307 - val_mae: 3.0236 - val_mape: 123683352.0000\n",
            "14/14 - 1s - loss: 39.3637 - mse: 41.8307 - mae: 3.0236 - mape: 123683352.0000\n",
            "118/118 - 35s - loss: 69.0684 - mse: 68.8948 - mae: 3.8239 - mape: 121923176.0000 - val_loss: 38.4638 - val_mse: 34.4349 - val_mae: 2.9275 - val_mape: 75396768.0000\n",
            "14/14 - 1s - loss: 38.4638 - mse: 34.4349 - mae: 2.9275 - mape: 75396768.0000\n",
            "118/118 - 35s - loss: 59.7407 - mse: 59.6676 - mae: 3.3785 - mape: 112376104.0000 - val_loss: 32.4400 - val_mse: 34.5833 - val_mae: 2.3673 - val_mape: 56005584.0000\n",
            "14/14 - 1s - loss: 32.4400 - mse: 34.5833 - mae: 2.3673 - mape: 56005584.0000\n",
            "118/118 - 34s - loss: 68.0751 - mse: 68.0537 - mae: 3.7927 - mape: 102359928.0000 - val_loss: 43.2701 - val_mse: 42.8609 - val_mae: 3.0104 - val_mape: 79711336.0000\n",
            "14/14 - 1s - loss: 43.2701 - mse: 42.8609 - mae: 3.0104 - mape: 79711336.0000\n",
            "122/122 - 36s - loss: 70.1255 - mse: 70.0215 - mae: 3.6339 - mape: 121931456.0000 - val_loss: 29.6093 - val_mse: 29.5587 - val_mae: 2.7211 - val_mape: 59441828.0000\n",
            "14/14 - 1s - loss: 29.6093 - mse: 29.5587 - mae: 2.7211 - mape: 59441828.0000\n",
            "118/118 - 34s - loss: 64.4391 - mse: 64.4972 - mae: 3.6129 - mape: 88620712.0000 - val_loss: 47.5870 - val_mse: 49.3984 - val_mae: 2.8183 - val_mape: 53841480.0000\n",
            "14/14 - 1s - loss: 47.5870 - mse: 49.3984 - mae: 2.8183 - mape: 53841480.0000\n",
            "118/118 - 35s - loss: 81.6287 - mse: 81.6369 - mae: 4.0554 - mape: 85019816.0000 - val_loss: 48.1339 - val_mse: 51.0046 - val_mae: 3.4935 - val_mape: 39016372.0000\n",
            "14/14 - 1s - loss: 48.1339 - mse: 51.0046 - mae: 3.4935 - mape: 39016372.0000\n",
            "118/118 - 35s - loss: 82.8729 - mse: 82.8947 - mae: 4.0042 - mape: 115318648.0000 - val_loss: 60.6040 - val_mse: 59.6279 - val_mae: 3.1322 - val_mape: 65383476.0000\n",
            "14/14 - 1s - loss: 60.6040 - mse: 59.6279 - mae: 3.1322 - mape: 65383476.0000\n",
            "118/118 - 35s - loss: 56.8310 - mse: 56.7718 - mae: 3.2489 - mape: 83525712.0000 - val_loss: 30.8771 - val_mse: 31.7321 - val_mae: 2.5499 - val_mape: 74512768.0000\n",
            "14/14 - 1s - loss: 30.8771 - mse: 31.7321 - mae: 2.5499 - mape: 74512768.0000\n",
            "118/118 - 36s - loss: 79.2717 - mse: 79.2569 - mae: 3.8761 - mape: 96813920.0000 - val_loss: 31.5958 - val_mse: 32.8228 - val_mae: 2.8316 - val_mape: 51296752.0000\n",
            "14/14 - 1s - loss: 31.5958 - mse: 32.8228 - mae: 2.8316 - mape: 51296752.0000\n",
            "118/118 - 35s - loss: 62.3452 - mse: 62.4040 - mae: 3.6568 - mape: 101898192.0000 - val_loss: 66.1167 - val_mse: 61.8008 - val_mae: 3.4982 - val_mape: 46463488.0000\n",
            "14/14 - 1s - loss: 66.1167 - mse: 61.8008 - mae: 3.4982 - mape: 46463488.0000\n",
            "118/118 - 36s - loss: 64.2492 - mse: 64.2917 - mae: 3.7056 - mape: 76176048.0000 - val_loss: 44.4509 - val_mse: 47.4098 - val_mae: 3.1087 - val_mape: 70679568.0000\n",
            "14/14 - 1s - loss: 44.4509 - mse: 47.4098 - mae: 3.1087 - mape: 70679568.0000\n",
            "118/118 - 35s - loss: 55.6536 - mse: 55.6989 - mae: 3.4524 - mape: 76198776.0000 - val_loss: 35.4416 - val_mse: 37.5323 - val_mae: 2.7781 - val_mape: 58064320.0000\n",
            "14/14 - 1s - loss: 35.4416 - mse: 37.5323 - mae: 2.7781 - mape: 58064320.0000\n",
            "118/118 - 35s - loss: 70.0090 - mse: 70.0518 - mae: 3.7305 - mape: 89152816.0000 - val_loss: 35.5162 - val_mse: 37.8322 - val_mae: 2.9821 - val_mape: 41680760.0000\n",
            "14/14 - 1s - loss: 35.5162 - mse: 37.8322 - mae: 2.9821 - mape: 41680760.0000\n",
            "118/118 - 35s - loss: 65.1964 - mse: 65.1417 - mae: 3.7525 - mape: 61685804.0000 - val_loss: 55.4075 - val_mse: 58.7099 - val_mae: 3.2358 - val_mape: 62892700.0000\n",
            "14/14 - 1s - loss: 55.4075 - mse: 58.7099 - mae: 3.2358 - mape: 62892700.0000\n",
            "118/118 - 35s - loss: 73.2433 - mse: 73.3339 - mae: 3.7815 - mape: 79018288.0000 - val_loss: 37.3606 - val_mse: 38.9907 - val_mae: 2.9683 - val_mape: 95531816.0000\n",
            "14/14 - 1s - loss: 37.3606 - mse: 38.9907 - mae: 2.9683 - mape: 95531816.0000\n",
            "118/118 - 35s - loss: 73.1551 - mse: 73.1325 - mae: 3.9359 - mape: 98749056.0000 - val_loss: 45.1296 - val_mse: 47.0916 - val_mae: 3.2521 - val_mape: 75741200.0000\n",
            "14/14 - 1s - loss: 45.1296 - mse: 47.0916 - mae: 3.2521 - mape: 75741200.0000\n",
            "118/118 - 35s - loss: 61.0864 - mse: 61.1125 - mae: 3.4859 - mape: 72772840.0000 - val_loss: 56.3554 - val_mse: 55.5000 - val_mae: 3.3221 - val_mape: 60077152.0000\n",
            "14/14 - 1s - loss: 56.3554 - mse: 55.5000 - mae: 3.3221 - mape: 60077152.0000\n",
            "122/122 - 36s - loss: 75.5512 - mse: 75.8505 - mae: 4.0522 - mape: 84132568.0000 - val_loss: 35.4839 - val_mse: 33.1276 - val_mae: 2.8134 - val_mape: 64114900.0000\n",
            "14/14 - 1s - loss: 35.4839 - mse: 33.1276 - mae: 2.8134 - mape: 64114900.0000\n",
            "118/118 - 36s - loss: 73.8875 - mse: 73.9583 - mae: 3.6462 - mape: 85624432.0000 - val_loss: 38.1725 - val_mse: 40.2079 - val_mae: 3.2690 - val_mape: 58310572.0000\n",
            "14/14 - 1s - loss: 38.1725 - mse: 40.2079 - mae: 3.2690 - mape: 58310572.0000\n",
            "118/118 - 35s - loss: 69.9462 - mse: 70.0318 - mae: 3.6873 - mape: 67569592.0000 - val_loss: 28.2132 - val_mse: 29.7343 - val_mae: 2.7113 - val_mape: 40011636.0000\n",
            "14/14 - 1s - loss: 28.2132 - mse: 29.7343 - mae: 2.7113 - mape: 40011636.0000\n",
            "118/118 - 34s - loss: 69.3454 - mse: 69.1132 - mae: 3.7419 - mape: 82539128.0000 - val_loss: 38.8791 - val_mse: 41.0160 - val_mae: 3.0589 - val_mape: 57113332.0000\n",
            "14/14 - 1s - loss: 38.8791 - mse: 41.0160 - mae: 3.0589 - mape: 57113332.0000\n",
            "118/118 - 35s - loss: 56.2727 - mse: 56.2974 - mae: 3.3407 - mape: 101598328.0000 - val_loss: 30.5105 - val_mse: 32.4057 - val_mae: 2.6970 - val_mape: 83220376.0000\n",
            "14/14 - 1s - loss: 30.5105 - mse: 32.4057 - mae: 2.6970 - mape: 83220376.0000\n",
            "118/118 - 35s - loss: 48.1227 - mse: 48.1401 - mae: 3.1121 - mape: 80902840.0000 - val_loss: 43.8510 - val_mse: 45.6363 - val_mae: 2.8524 - val_mape: 54539972.0000\n",
            "14/14 - 1s - loss: 43.8510 - mse: 45.6363 - mae: 2.8524 - mape: 54539972.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crfKfATfoRlC",
        "colab_type": "code",
        "outputId": "f357e98e-7925-4647-d47a-47662c633e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(val_loss/len(loop_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.078838747739792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSGOU3X77riQ",
        "colab_type": "code",
        "outputId": "6b44c618-ec8d-423c-b4fe-38d4adfafa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# using the last batch to print the evaluation results\n",
        "val_metric = model.evaluate(X_tr, y_tr, verbose=2)\n",
        "val_metric = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(val_metric)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118/118 - 10s - loss: 28.9225 - mse: 28.9519 - mae: 2.5114 - mape: 54113184.0000\n",
            "14/14 - 1s - loss: 43.8510 - mse: 45.6363 - mae: 2.8524 - mape: 54539972.0000\n",
            "[43.850975036621094, 45.636314392089844, 2.8524367809295654, 54539972.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQAZKsL2EdV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# delete useless data preventing memory crashes\n",
        "del history\n",
        "del split_list\n",
        "del new_select_grouper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Um-nMga6fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data preprocessing for the test data\n",
        "# Read data in 2019 from google drive\n",
        "data_path = '/content/gdrive/My Drive/ctx/combine_data/2019test/All_Demand_2019_3months.csv'\n",
        "new_select_data = pd.read_csv(data_path)\n",
        "\n",
        "# Using 'pickup_time_g' to create index which will be used later to aggregate data\n",
        "new_select_data['pickup_time_g_index'] = pd.to_datetime(new_select_data['pickup_time_g']) \n",
        "new_select_data['pickup_time_g'] = new_select_data['pickup_time_g_index'].copy()\n",
        "new_select_data.set_index('pickup_time_g_index',inplace=True)\n",
        "# Aggregate data using LocationID \n",
        "new_select_grouper = new_select_data.groupby('LocationID')\n",
        "\n",
        "# Randomly select 1% data in 2019 and change 'day','weekday', 'hour','minute','LocationID','minute_demand' and '15_demand' into categorical again\n",
        "train_data, label_data = [],[]\n",
        "for each_loc in new_select_grouper:\n",
        "  location_data = each_loc[1]\n",
        "  first_time = True\n",
        "# Here 'random_state' was set into 2020 and the test dataset used in other two models also getting from random_state 2020, which make sure the identical test dataset has been used\n",
        "  location_data_sample = location_data.sample(frac=0.001, random_state=2020)\n",
        "  for index, row in location_data_sample.iterrows():\n",
        "    this_time = row['pickup_time_g']\n",
        "# Getting previous 45 mins data and when adjusting timestep, also change 'timedelta(minutes=45)' into 15, 30, 60, 65, 90\n",
        "    time_window = (location_data['pickup_time_g']>=this_time - timedelta(minutes=45))&(location_data['pickup_time_g']<=this_time - timedelta(minutes=1))\n",
        "    window_items = location_data[time_window]\n",
        "# when adjusting timestep, also change 'len(window_items) ==  45' into 15, 30, 60, 65, 90\n",
        "    if len(window_items) == 45:\n",
        "        pu_day_cat = to_categorical(window_items['day'], num_classes=32)\n",
        "        pu_week_cat = to_categorical(window_items['weekday'], num_classes=7)\n",
        "        hour_cat = to_categorical(window_items['hour'], num_classes=25)\n",
        "        minute_cat = to_categorical(window_items['minute'], num_classes=60)\n",
        "        if first_time:\n",
        "          first_time = False\n",
        "          locat_cat = to_categorical(window_items['LocationID'], num_classes=265)\n",
        "        train_data.append(np.hstack((pu_day_cat,pu_week_cat,hour_cat,minute_cat,locat_cat,\n",
        "                                    window_items['minute_demand'].values.reshape(-1,1))))\n",
        "        label_data.append(row['15_demand'])\n",
        "\n",
        "# using data to test the model\n",
        "train_data = np.array(train_data)\n",
        "label_data = np.array(label_data)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(train_data, label_data, test_size=0.1, random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ximf58OsbMYr",
        "colab_type": "code",
        "outputId": "6b0f849f-6fe6-4316-8256-b11141dfb0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Print the evaluation result \n",
        "test_metric = model.evaluate(X_val, y_val, verbose=2)\n",
        "print(test_metric)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 - 5s - loss: 24.1127 - mse: 24.3388 - mae: 2.3704 - mape: 84099960.0000\n",
            "[24.112661361694336, 24.33879280090332, 2.370351791381836, 84099960.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1MX2Rg_ijkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw line chart: LSTM with different timestep\n",
        "import matplotlib.pyplot as plt\n",
        "timestep=[15,30,45,60,75,90]\n",
        "mae=[2.5711,2.6834,2.3878,2.5384,2.4785,2.5003]\n",
        "plt.plot(timestep,mae,color=\"blue\", linestyle=\"-\", marker=\"^\", linewidth=1)\n",
        "plt.xlabel(\"Timestep\")\n",
        "plt.ylabel(\"test_MAE\")\n",
        "plt.title(\"LSTM with different timestep\")\n",
        "plt.grid(True)\n",
        "plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESpDgLeE_-zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw line chart: Timestep comparison between LSTM and GRU\n",
        "lstmtmae = [2.5711,2.6834,2.3878,2.5384,2.4785,2.5003]\n",
        "grutmae = [2.4362,2.9012,2.4827,2.3944,2.5205,2.4537]\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('test_MAE')\n",
        "x = [15,30,45,60,75,90]\n",
        "plt.plot(x,lstmtmae,\"x-\",label=\"LSTM\")\n",
        "plt.plot(x,grutmae,\"+-\",label=\"GRU\") \n",
        "plt.grid(True)\n",
        "plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
        "plt.title(\"Timestep comparison between LSTM and GRU\")\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(0.2, 0.95))\n",
        "plt.annotate('Timestep 45', xy=(45, 2.3878), xytext=(45, 2.6), arrowprops=dict(facecolor='k', headwidth=5, width=0.5))\n",
        "plt.annotate('Timestep 15', xy=(15, 2.4362), xytext=(12, 2.2), arrowprops=dict(facecolor='k', headwidth=5, width=0.5))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHDv52bwARz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw line chart: Learning_rate comparsion between LSTM and GRU\n",
        "import matplotlib.pyplot as plt\n",
        "lstmtmae = [2.5711,2.7170,2.6733]\n",
        "grutmae = [2.4362,2.5580,2.4449]\n",
        "plt.xlabel('Learning_rate')\n",
        "plt.ylabel('test_MAE')\n",
        "x = [0.0001,0.0005,0.001]\n",
        "plt.plot(x,lstmtmae,\"x-\",label=\"LSTM\")\n",
        "plt.plot(x,grutmae,\"+-\",label=\"GRU\")\n",
        "plt.grid(True)\n",
        "plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
        "plt.title('Learning_rate comparsion between LSTM and GRU')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}